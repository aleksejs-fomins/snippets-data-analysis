{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from operator import xor\n",
    "import readFloatsFile\n",
    "from JidtWrapper import JidtWrapper, np2JArr\n",
    "\n",
    "# Create a TE wrapper class\n",
    "jidtWrapper1 = JidtWrapper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytical transfer entropy:\n",
    "\n",
    "* $T(A\\rightarrow B) = I(Y_t ; X_{t \\in [-1, -L]} | Y_{t \\in [-1, -L]})$\n",
    "  - The information shared by current Y, and history of X of length L, given that the history of Y of length L is known\n",
    "\n",
    "Additional concepts\n",
    "* https://github.com/jlizier/jidt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original array:       [ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      "lossy-shifted by 2:   [0. 0. 1. 2. 3. 4. 5. 6. 7. 8.]\n",
      "cyclic-shifted by 2:  [ 9. 10.  1.  2.  3.  4.  5.  6.  7.  8.]\n"
     ]
    }
   ],
   "source": [
    "# Shift all elements of the array to the right cyclically\n",
    "def cyclicShift(arr, num):\n",
    "    return np.hstack((arr[-num:], arr[:-num]))\n",
    "\n",
    "# Shift all elements of the array to the right, replacing them with zeros\n",
    "def lossyShift(arr, num):\n",
    "    return np.hstack(([0]*num, arr[:-num]))\n",
    "\n",
    "aaa = np.linspace(1, 10, 10)\n",
    "print(\"original array:      \", aaa)\n",
    "print(\"lossy-shifted by 2:  \", lossyShift(aaa, 2))\n",
    "print(\"cyclic-shifted by 2: \", cyclicShift(aaa, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: TE for Two-Partite Binary Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncorrelated: 0.0018\n",
      "1 step lag  : 0.9490\n",
      "2 step lag  : 0.0184\n",
      "1 step lag, backwards  : 0.0110\n",
      "2 step lag, backwards  : 0.0110\n"
     ]
    }
   ],
   "source": [
    "# Generate some random binary data.\n",
    "sourceArray1 = np.random.randint(0, 2, 100)\n",
    "sourceArray2 = np.random.randint(0, 2, 100)\n",
    "destArray1 = lossyShift(sourceArray1, 1).astype(int)\n",
    "destArray2 = lossyShift(sourceArray1, 2).astype(int)\n",
    "\n",
    "# Create a TE calculator and run it:\n",
    "param = {'historyLength' : 2, 'kernelWidth' : 1}\n",
    "te_random = jidtWrapper1.calcTwoPartiteTE_Discrete(sourceArray2, destArray1, param)\n",
    "te_lag_1 = jidtWrapper1.calcTwoPartiteTE_Discrete(sourceArray1, destArray1, param)\n",
    "te_lag_2 = jidtWrapper1.calcTwoPartiteTE_Discrete(sourceArray1, destArray2, param)\n",
    "te_lag_1_rev = jidtWrapper1.calcTwoPartiteTE_Discrete(destArray1, sourceArray1, param)\n",
    "te_lag_2_rev = jidtWrapper1.calcTwoPartiteTE_Discrete(destArray2, sourceArray1,param)\n",
    "\n",
    "print(\"Uncorrelated: %.4f\" % te_random)\n",
    "print(\"1 step lag  : %.4f\" % te_lag_1)\n",
    "print(\"2 step lag  : %.4f\" % te_lag_2)\n",
    "print(\"1 step lag, backwards  : %.4f\" % te_lag_1_rev)\n",
    "print(\"2 step lag, backwards  : %.4f\" % te_lag_1_rev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: TE for Multidimensional Two-Partite Binary Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result should be close to 1 bit here, since we are executing copy operations of what is effectively a random bit to each cell here: 0.996 bits from 100 observations\n"
     ]
    }
   ],
   "source": [
    "nData = 100\n",
    "\n",
    "# First row is random\n",
    "# 2nd row is the first row offset to the right by 1\n",
    "rowData = np.zeros((2, nData), dtype=int)\n",
    "rowData[0] = np.random.randint(0, 2, nData)\n",
    "rowData[1] = np.hstack((rowData[0, nData-1], rowData[0, 0:nData-1]))\n",
    "\n",
    "# Add observations of transfer across one cell to the right per time step:\n",
    "param = {'historyLength' : 2, 'kernelWidth' : 1}\n",
    "result2D = jidtWrapper1.calcTwoPartiteTE_Discrete(rowData, 1, param)\n",
    "nObserv = jidtWrapper1.javaClass.getNumObservations()\n",
    "print(('The result should be close to 1 bit here, since we are executing copy ' + \\\n",
    "      'operations of what is effectively a random bit to each cell here: %.3f ' + \\\n",
    "      'bits from %d observations') % (result2D, nObserv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: TE for Continuous Data Kernel\n",
    "\n",
    "For copied source, should give something close to 1 bit: Expected correlation is expected covariance / product of expected standard deviations: (where square of destArray standard dev is sum of squares of std devs of underlying distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TE result 0.3522 bits; expected to be close to 0.2653 bits for these correlated Gaussians but biased upwards\n",
      "TE result 0.0886 bits; expected to be close to 0 bits for uncorrelated Gaussians but will be biased upwards\n"
     ]
    }
   ],
   "source": [
    "# Generate some random normalised data.\n",
    "numObservations = 1000\n",
    "covariance = 0.4\n",
    "\n",
    "# Make two uncorrelated normal-distributed sources\n",
    "sourceArray  = np.random.normal(0, 1, numObservations)\n",
    "sourceArray2 = np.random.normal(0, 1, numObservations)\n",
    "\n",
    "# Destination array of random normals with partial correlation to previous value of sourceArray\n",
    "destArray = np.zeros(numObservations)\n",
    "destArray[1:] += covariance * sourceArray[:-1]\n",
    "destArray[1:] += (1 - covariance) * np.random.normal(0, 1, numObservations-1)\n",
    "\n",
    "# Normalise the individual variables\n",
    "# Use history length 1 (Schreiber k=1), kernel width of 0.5 normalised units\n",
    "param = {'method': 'TE_KERNEL', 'initParam': [1, 0.5], 'properties': {\"NORMALISE\" : \"true\"}}\n",
    "result1 = jidtWrapper1.runJavaTwoPartite((sourceArray, destArray), param)\n",
    "result2 = jidtWrapper1.runJavaTwoPartite((sourceArray2, destArray), param)\n",
    "\n",
    "corr_expected = covariance / (1 * np.sqrt(covariance**2 + (1-covariance)**2))\n",
    "rez_expected = -0.5*np.log(1-np.power(corr_expected, 2)) / np.log(2)\n",
    "print(\"TE result %.4f bits; expected to be close to %.4f bits for these correlated Gaussians but biased upwards\" % (result1, rez_expected))\n",
    "print(\"TE result %.4f bits; expected to be close to 0 bits for uncorrelated Gaussians but will be biased upwards\" % result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4: TE for Continuous Data Kraskov\n",
    "\n",
    "Note that the calculation is a random variable (because the generated data is a set of random variables) - the result will be of the order of what we expect, but not exactly equal to it; in fact, there will be a large variance around it. Expected correlation is expected covariance / product of expected standard deviations: (where square of destArray standard dev is sum of squares of std devs of underlying distributions)\n",
    "\n",
    "Perform calculation with a correlated and an uncorrelated source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TE result 0.2153 nats; expected to be close to 0.1839 nats for these correlated Gaussians\n",
      "TE result -0.0034 nats; expected to be close to 0 nats for these uncorrelated Gaussians\n"
     ]
    }
   ],
   "source": [
    "# Generate some random normalised data.\n",
    "numObservations = 1000\n",
    "covariance = 0.4\n",
    "\n",
    "# Make two uncorrelated normal-distributed sources\n",
    "sourceArray  = np.random.normal(0, 1, numObservations)\n",
    "sourceArray2 = np.random.normal(0, 1, numObservations)\n",
    "\n",
    "# Destination array of random normals with partial correlation to previous value of sourceArray\n",
    "destArray = np.zeros(numObservations)\n",
    "destArray[1:] += covariance * sourceArray[:-1]\n",
    "destArray[1:] += (1 - covariance) * np.random.normal(0, 1, numObservations-1)\n",
    "\n",
    "# Create a TE calculator and run it:\n",
    "# Use Kraskov parameter K=4 for 4 nearest points\n",
    "param = {'method': 'TE_KRASKOV', 'initParam': [1], 'properties': {\"NORMALISE\": \"true\", \"k\": \"4\"}}\n",
    "result1 = jidtWrapper1.runJavaTwoPartite((sourceArray, destArray), param)   \n",
    "result2 = jidtWrapper1.runJavaTwoPartite((sourceArray2, destArray), param)\n",
    "\n",
    "corr_expected = covariance / (1 * np.sqrt(covariance**2 + (1-covariance)**2))\n",
    "rez_expected = -0.5*np.log(1-np.power(corr_expected, 2))\n",
    "print(\"TE result %.4f nats; expected to be close to %.4f nats for these correlated Gaussians\" % (result1, rez_expected))\n",
    "print(\"TE result %.4f nats; expected to be close to 0 nats for these uncorrelated Gaussians\" % result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 5: TE Binary Multivariate Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For source which the 2 bits are determined from, result should be close to 2 bits : 1.922\n",
      "For random source, result should be close to 0 bits in theory: 0.396\n",
      "The result for random source is inflated towards 0.3 due to finite observation length (100).One can verify that the answer is consistent with that from a random source by checking:teCalc.computeSignificance(1000); ans.pValue\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate some random binary data.\n",
    "numRows = 2\n",
    "numObservations = 100\n",
    "sourceArray1 = np.random.randint(0, 2, numRows*numObservations).reshape((numObservations, numRows))\n",
    "sourceArray2 = np.random.randint(0, 2, numRows*numObservations).reshape((numObservations, numRows))\n",
    "\n",
    "# Destination variable takes a copy of the first bit of the source in bit 1,\n",
    "#  and an XOR of the two bits of the source in bit 2:\n",
    "destArray = np.zeros((numObservations, numRows), dtype=int)\n",
    "destArray[1:, 0] = sourceArray1[:-1, 0]\n",
    "destArray[1:, 1] = xor(sourceArray1[:-1, 0], sourceArray1[:-1, 1])\n",
    "\n",
    "# We need to construct the joint values of the dest and source before we pass them in,\n",
    "#  and need to use the matrix conversion routine when calling from Matlab/Octave:\n",
    "sourceArray1Combined = jidtWrapper1.computeCombinedValues(sourceArray1)\n",
    "sourceArray2Combined = jidtWrapper1.computeCombinedValues(sourceArray2)\n",
    "destArrayCombined    = jidtWrapper1.computeCombinedValues(destArray)\n",
    "\n",
    "param = {'historyLength' : 4, 'kernelWidth' : 1}\n",
    "result1 = jidtWrapper1.calcTwoPartiteTE_Discrete(sourceArray1Combined, destArrayCombined, param)\n",
    "result2 = jidtWrapper1.calcTwoPartiteTE_Discrete(sourceArray2Combined, destArrayCombined, param)\n",
    "\n",
    "print('For source which the 2 bits are determined from, result should be close to 2 bits : %.3f' % result1)\n",
    "print('For random source, result should be close to 0 bits in theory: %.3f' % result2)\n",
    "print('The result for random source is inflated towards 0.3 due to finite observation length (%d).'\n",
    "      'One can verify that the answer is consistent with that from a random source by checking:'\n",
    "      'teCalc.computeSignificance(1000); ans.pValue\\n' % numObservations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 6: Dynamic Calling Mutual Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: MI_MV_KRASKOV ; MI of two univariate variables=0.100 , joint 2D variables=0.364\n",
      "Estimator: MI_MV_KERNEL ; MI of two univariate variables=0.159 , joint 2D variables=1.120\n",
      "Estimator: MI_MV_Gaussian ; MI of two univariate variables=0.089 , joint 2D variables=0.297\n"
     ]
    }
   ],
   "source": [
    "datafile = os.path.join(os.getcwd(), 'data/4ColsPairedNoisyDependence-1.txt')\n",
    "data = np.array(readFloatsFile.readFloatsFile(datafile))\n",
    "\n",
    "MI_ESTIMATOR_LIST = [\"MI_MV_KRASKOV\", \"MI_MV_KERNEL\", \"MI_MV_Gaussian\"]\n",
    "for miEst in MI_ESTIMATOR_LIST:\n",
    "    paramUniVar = {'method': miEst, 'initParam': [1, 1], 'properties': {}, 'NO_CONV_JARRAY' : True}\n",
    "    paramJoint  = {'method': miEst, 'initParam': [2, 2], 'properties': {}, 'NO_CONV_JARRAY' : True}\n",
    "    miUniVar = jidtWrapper1.runJavaTwoPartite((data[:, 0], data[:, 2]), paramUniVar)\n",
    "    miJoint  = jidtWrapper1.runJavaTwoPartite((data[:, [0, 1]], data[:, [2, 3]]), paramJoint)\n",
    "\n",
    "    print(\"Estimator:\", miEst,\"; MI of two univariate variables=%.3f\" % miUniVar, \", joint 2D variables=%.3f\" % miJoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 9 - Transfer entropy on continuous data using Kraskov estimators with auto-embedding\n",
    "\n",
    "Transfer entropy (TE) calculation on continuous-valued data using the Kraskov-estimator TE calculator, with automatic selection of embedding parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TE(breath->heart) was 0.052 nats for (heart embedding:) k=2, k_tau=1, \n",
      "(breath embedding:) l=5,l_tau=1, optimised via Ragwitz criteria \n",
      "\n",
      "TE(breath->heart) was 0.052 nats for (heart embedding:) k=2, k_tau=1, \n",
      "optimised via Ragwitz criteria, plus (breath embedding:) l=1,l_tau=1\n"
     ]
    }
   ],
   "source": [
    "# Examine the heart-breath interaction that Schreiber originally looked at:\n",
    "datafile = 'data/SFI-heartRate_breathVol_bloodOx.txt'\n",
    "data = np.array(readFloatsFile.readFloatsFile(datafile))\n",
    "\n",
    "# Select data points 2350:3550, pulling out the relevant columns:\n",
    "breathRate = data[2350:3551,1]; \n",
    "heartRate = data[2350:3551,0];\n",
    "\n",
    "\n",
    "# Set properties for auto-embedding of both source and destination using the Ragwitz criteria:\n",
    "#  a. Auto-embedding method\n",
    "#  b. Search range for embedding dimension (k) and delay (tau)\n",
    "teCalcClass = jidtWrapper1.getJavaClass(\"TE_KRASKOV\")\n",
    "param = {'method': 'TE_KRASKOV', 'initParam': (), 'properties': {\n",
    "    teCalcClass.PROP_AUTO_EMBED_METHOD: teCalcClass.AUTO_EMBED_METHOD_RAGWITZ,\n",
    "    teCalcClass.PROP_K_SEARCH_MAX: \"6\",\n",
    "    teCalcClass.PROP_TAU_SEARCH_MAX: \"6\"\n",
    "}}\n",
    "\n",
    "teBreathToHeart = jidtWrapper1.runJavaTwoPartite((breathRate, heartRate), param)  \n",
    "\n",
    "# Check the auto-selected parameters and print out the result:\n",
    "optimisedK    = int(jidtWrapper1.javaClass.getProperty(teCalcClass.K_PROP_NAME))\n",
    "optimisedKTau = int(jidtWrapper1.javaClass.getProperty(teCalcClass.K_TAU_PROP_NAME))\n",
    "optimisedL    = int(jidtWrapper1.javaClass.getProperty(teCalcClass.L_PROP_NAME))\n",
    "optimisedLTau = int(jidtWrapper1.javaClass.getProperty(teCalcClass.L_TAU_PROP_NAME))\n",
    "\n",
    "print(\"TE(breath->heart) was %.3f nats for \" % teBreathToHeart, end='')\n",
    "print(\"(heart embedding:) k=%d, k_tau=%d, \" % (optimisedK, optimisedKTau))\n",
    "print(\"(breath embedding:) l=%d,l_tau=%d, \" % (optimisedL, optimisedLTau), end='')\n",
    "print(\"optimised via Ragwitz criteria \\n\")\n",
    "\n",
    "\n",
    "\n",
    "# Next, embed the destination only using the Ragwitz criteria:\n",
    "# Since we're only auto-embedding the destination, we supply\n",
    "#  source embedding here (to overwrite the auto embeddings from above):\n",
    "param = {'method': 'TE_KRASKOV', 'initParam': (), 'properties': {\n",
    "    teCalcClass.PROP_AUTO_EMBED_METHOD: teCalcClass.AUTO_EMBED_METHOD_RAGWITZ_DEST_ONLY,\n",
    "    teCalcClass.PROP_K_SEARCH_MAX: \"6\",\n",
    "    teCalcClass.PROP_TAU_SEARCH_MAX: \"6\",\n",
    "    teCalcClass.L_PROP_NAME: \"1\",\n",
    "    teCalcClass.L_TAU_PROP_NAME: \"1\"\n",
    "}}\n",
    "\n",
    "teBreathToHeartDestEmbedding = jidtWrapper1.runJavaTwoPartite((breathRate, heartRate), param) \n",
    "\n",
    "# Check the auto-selected parameters and print out the result:\n",
    "optimisedK    = int(jidtWrapper1.javaClass.getProperty(teCalcClass.K_PROP_NAME))\n",
    "optimisedKTau = int(jidtWrapper1.javaClass.getProperty(teCalcClass.K_TAU_PROP_NAME))\n",
    "\n",
    "print(\"TE(breath->heart) was %.3f nats for \" % teBreathToHeart, end='')\n",
    "print(\"(heart embedding:) k=%d, k_tau=%d, \" % (optimisedK, optimisedKTau))\n",
    "print(\"optimised via Ragwitz criteria, plus (breath embedding:) l=1,l_tau=1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
